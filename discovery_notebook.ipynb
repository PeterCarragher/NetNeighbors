{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Section 1: Environment Setup (Run Once)\n",
    "\n",
    "### Check Available RAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import psutil\n",
    "\n",
    "# Check available RAM\n",
    "ram_gb = psutil.virtual_memory().total / (1024**3)\n",
    "print(f\"Available RAM: {ram_gb:.1f} GB\")\n",
    "\n",
    "if ram_gb < 20:\n",
    "    print(\"\\n‚ö†Ô∏è WARNING: You need Colab Pro for this notebook!\")\n",
    "    print(\"   Required: 20GB+ RAM\")\n",
    "    print(f\"   You have: {ram_gb:.1f} GB\")\n",
    "    print(\"\\n   Please enable High-RAM runtime:\")\n",
    "    print(\"   Runtime ‚Üí Change runtime type ‚Üí Runtime shape: High-RAM\")\n",
    "    raise Exception(\"Insufficient RAM. Please upgrade runtime.\")\n",
    "else:\n",
    "    print(\"‚úÖ Sufficient RAM available\")\n",
    "    print(\"\\nYou can proceed with setup!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mount Google Drive (Optional but Recommended)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "import os\n",
    "\n",
    "# Ask user if they want to mount Drive\n",
    "print(\"Mount Google Drive to cache webgraph between sessions?\")\n",
    "print(\"This saves ~15 minutes on future runs.\")\n",
    "print(\"\")\n",
    "mount_choice = input(\"Mount Google Drive? (yes/no): \").lower().strip()\n",
    "\n",
    "if mount_choice in ['yes', 'y']:\n",
    "    drive.mount('/content/drive')\n",
    "    WEBGRAPH_DIR = '/content/drive/MyDrive/Colab_Data/webgraph'\n",
    "    print(f\"\\n‚úÖ Webgraph will be cached in: {WEBGRAPH_DIR}\")\n",
    "    print(\"This will persist across sessions!\")\n",
    "else:\n",
    "    WEBGRAPH_DIR = '/content/webgraph'\n",
    "    print(f\"\\n‚ö†Ô∏è Webgraph will be downloaded each session (~15 min)\")\n",
    "    print(f\"Stored temporarily in: {WEBGRAPH_DIR}\")\n",
    "\n",
    "# Create directory\n",
    "os.makedirs(WEBGRAPH_DIR, exist_ok=True)\n",
    "print(f\"\\nDirectory created: {WEBGRAPH_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install Java 17"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "echo \"Installing Java 17...\"\n",
    "apt-get update -qq > /dev/null 2>&1\n",
    "apt-get install -y -qq openjdk-17-jdk-headless maven > /dev/null 2>&1\n",
    "\n",
    "echo \"‚úÖ Java installation complete\"\n",
    "java -version"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download & Build Tools\n",
    "\n",
    "This cell clones two repositories:\n",
    "1. **cc-webgraph** - CommonCrawl's webgraph processing tools (provides BVGraph library)\n",
    "2. **NetNeighbors** - The discovery tool for this notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "# Clone and build cc-webgraph\n",
    "if [ ! -d \"cc-webgraph\" ]; then\n",
    "    echo \"Cloning cc-webgraph repository...\"\n",
    "    git clone --depth 1 https://github.com/commoncrawl/cc-webgraph.git > /dev/null 2>&1\n",
    "    \n",
    "    echo \"Building cc-webgraph (this may take 1-2 minutes)...\"\n",
    "    cd cc-webgraph\n",
    "    mvn clean package -DskipTests -q\n",
    "    \n",
    "    echo \"‚úÖ cc-webgraph built successfully\"\n",
    "else\n",
    "    echo \"‚úÖ cc-webgraph already exists\"\n",
    "fi\n",
    "\n",
    "# Clone NetNeighbors (contains the discovery tool)\n",
    "if [ ! -d \"NetNeighbors\" ]; then\n",
    "    echo \"\"\n",
    "    echo \"Cloning NetNeighbors discovery tool...\"\n",
    "    git clone --depth 1 https://github.com/PeterCarragher/NetNeighbors.git > /dev/null 2>&1\n",
    "    \n",
    "    echo \"Compiling DiscoveryTool...\"\n",
    "    mkdir -p NetNeighbors/bin\n",
    "    javac -cp \"cc-webgraph/target/cc-webgraph-0.1-SNAPSHOT-jar-with-dependencies.jar\" \\\n",
    "        -d NetNeighbors/bin \\\n",
    "        NetNeighbors/src/DiscoveryTool.java\n",
    "    \n",
    "    echo \"‚úÖ NetNeighbors tools ready\"\n",
    "else\n",
    "    echo \"‚úÖ NetNeighbors already exists\"\n",
    "fi\n",
    "\n",
    "# Verify JAR and class files exist\n",
    "echo \"\"\n",
    "if [ -f \"cc-webgraph/target/cc-webgraph-0.1-SNAPSHOT-jar-with-dependencies.jar\" ]; then\n",
    "    echo \"‚úÖ cc-webgraph JAR found\"\n",
    "else\n",
    "    echo \"‚ùå cc-webgraph JAR not found\"\n",
    "fi\n",
    "\n",
    "if [ -f \"NetNeighbors/bin/DiscoveryTool.class\" ]; then\n",
    "    echo \"‚úÖ DiscoveryTool compiled\"\n",
    "else\n",
    "    echo \"‚ùå DiscoveryTool not compiled\"\n",
    "fi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Download CommonCrawl Webgraph (~10 minutes)\n",
    "\n",
    "Downloads pre-built graph files directly from CommonCrawl (~23GB total):\n",
    "- Domain vertices mapping\n",
    "- Forward graph (BVGraph format) for outlinks\n",
    "- Transpose graph for backlinks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.auto import tqdm\n",
    "import urllib.request\n",
    "\n",
    "VERSION = \"cc-main-2025-26-nov-dec-jan\"\n",
    "BASE_URL = f\"https://data.commoncrawl.org/projects/hyperlinkgraph/{VERSION}/domain\"\n",
    "\n",
    "# Pre-built graph files from CommonCrawl (no need to build ourselves!)\n",
    "files_to_download = [\n",
    "    # Domain mapping (required for lookups)\n",
    "    (f\"{VERSION}-domain-vertices.txt.gz\", \"871 MB\"),\n",
    "    # Pre-built BVGraph (for outlinks)\n",
    "    (f\"{VERSION}-domain.graph\", \"10.9 GB\"),\n",
    "    (f\"{VERSION}-domain.properties\", \"1.3 KB\"),\n",
    "    # Transpose graph (for backlinks)\n",
    "    (f\"{VERSION}-domain-t.graph\", \"11.2 GB\"),\n",
    "    (f\"{VERSION}-domain-t.properties\", \"1.3 KB\"),\n",
    "    # Statistics (small, useful metadata)\n",
    "    (f\"{VERSION}-domain.stats\", \"788 B\"),\n",
    "]\n",
    "\n",
    "def download_with_progress(url, dest_path, expected_size=\"\"):\n",
    "    \"\"\"Download file with progress bar\"\"\"\n",
    "    if os.path.exists(dest_path):\n",
    "        size_mb = os.path.getsize(dest_path) / (1024 * 1024)\n",
    "        print(f\"‚úÖ Already exists: {os.path.basename(dest_path)} ({size_mb:.1f} MB)\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Downloading: {os.path.basename(dest_path)} ({expected_size})\")\n",
    "    \n",
    "    def progress_hook(pbar):\n",
    "        def update(block_num, block_size, total_size):\n",
    "            if total_size > 0:\n",
    "                pbar.total = total_size\n",
    "                pbar.update(block_size)\n",
    "        return update\n",
    "    \n",
    "    with tqdm(unit='B', unit_scale=True, unit_divisor=1024) as pbar:\n",
    "        urllib.request.urlretrieve(url, dest_path, reporthook=progress_hook(pbar))\n",
    "    \n",
    "    print(f\"‚úÖ Downloaded: {os.path.basename(dest_path)}\")\n",
    "\n",
    "print(\"Downloading CommonCrawl webgraph (pre-built graph files)...\")\n",
    "print(f\"Destination: {WEBGRAPH_DIR}\")\n",
    "print(f\"\\nTotal download: ~23 GB (includes transpose graph for backlinks)\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "for filename, size in files_to_download:\n",
    "    url = f\"{BASE_URL}/{filename}\"\n",
    "    dest = os.path.join(WEBGRAPH_DIR, filename)\n",
    "    download_with_progress(url, dest, size)\n",
    "\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"‚úÖ All graph files downloaded!\")\n",
    "print(\"\\nGraph files are pre-built by CommonCrawl - no build step needed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Verify Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import subprocess\n",
    "import gzip\n",
    "\n",
    "print(\"=\"*60)\n",
    "print(\"           INSTALLATION VERIFICATION\")\n",
    "print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "all_checks_passed = True\n",
    "\n",
    "# Check Java\n",
    "print(\"1. Java Runtime:\")\n",
    "try:\n",
    "    result = subprocess.run(['java', '-version'], capture_output=True, text=True, timeout=5)\n",
    "    if result.returncode == 0:\n",
    "        version_line = result.stderr.split('\\n')[0]\n",
    "        print(f\"   ‚úÖ {version_line}\")\n",
    "    else:\n",
    "        print(\"   ‚ùå Java not working properly\")\n",
    "        all_checks_passed = False\n",
    "except Exception as e:\n",
    "    print(f\"   ‚ùå Java error: {e}\")\n",
    "    all_checks_passed = False\n",
    "\n",
    "# Check cc-webgraph JAR\n",
    "print(\"\\n2. cc-webgraph Tools:\")\n",
    "jar_path = \"/content/cc-webgraph/target/cc-webgraph-0.1-SNAPSHOT-jar-with-dependencies.jar\"\n",
    "if os.path.exists(jar_path):\n",
    "    size_mb = os.path.getsize(jar_path) / (1024 * 1024)\n",
    "    print(f\"   ‚úÖ JAR file found ({size_mb:.1f} MB)\")\n",
    "else:\n",
    "    print(f\"   ‚ùå JAR file not found\")\n",
    "    all_checks_passed = False\n",
    "\n",
    "# Check DiscoveryTool\n",
    "print(\"\\n3. DiscoveryTool:\")\n",
    "tool_path = \"/content/NetNeighbors/bin/DiscoveryTool.class\"\n",
    "if os.path.exists(tool_path):\n",
    "    print(f\"   ‚úÖ DiscoveryTool compiled\")\n",
    "else:\n",
    "    print(f\"   ‚ùå DiscoveryTool not found\")\n",
    "    all_checks_passed = False\n",
    "\n",
    "# Check webgraph data files\n",
    "print(\"\\n4. Webgraph Data Files:\")\n",
    "VERSION = \"cc-main-2025-26-nov-dec-jan\"\n",
    "\n",
    "files_to_check = [\n",
    "    (f\"{VERSION}-domain-vertices.txt.gz\", \"Vertices (domain mapping)\"),\n",
    "    (f\"{VERSION}-domain.graph\", \"Forward graph (outlinks)\"),\n",
    "    (f\"{VERSION}-domain.properties\", \"Forward graph properties\"),\n",
    "    (f\"{VERSION}-domain-t.graph\", \"Transpose graph (backlinks)\"),\n",
    "    (f\"{VERSION}-domain-t.properties\", \"Transpose graph properties\"),\n",
    "    (f\"{VERSION}-domain.stats\", \"Graph statistics\"),\n",
    "]\n",
    "\n",
    "for filename, description in files_to_check:\n",
    "    filepath = os.path.join(WEBGRAPH_DIR, filename)\n",
    "    if os.path.exists(filepath):\n",
    "        size = os.path.getsize(filepath)\n",
    "        if size > 1024 * 1024 * 1024:  # > 1GB\n",
    "            size_str = f\"{size / (1024**3):.1f} GB\"\n",
    "        elif size > 1024 * 1024:  # > 1MB\n",
    "            size_str = f\"{size / (1024**2):.1f} MB\"\n",
    "        else:\n",
    "            size_str = f\"{size / 1024:.1f} KB\"\n",
    "        print(f\"   ‚úÖ {description}: {size_str}\")\n",
    "    else:\n",
    "        print(f\"   ‚ùå {description}: MISSING\")\n",
    "        all_checks_passed = False\n",
    "\n",
    "# Graph statistics\n",
    "print(\"\\n5. Graph Statistics:\")\n",
    "vertices_file = os.path.join(WEBGRAPH_DIR, f\"{VERSION}-domain-vertices.txt.gz\")\n",
    "if os.path.exists(vertices_file):\n",
    "    print(\"   Counting domains (this takes ~30 seconds)...\")\n",
    "    try:\n",
    "        with gzip.open(vertices_file, 'rt', encoding='utf-8') as f:\n",
    "            num_domains = sum(1 for _ in f)\n",
    "        print(f\"   ‚úÖ Total domains: {num_domains:,}\")\n",
    "    except Exception as e:\n",
    "        print(f\"   ‚ö†Ô∏è Could not count: {e}\")\n",
    "\n",
    "# Read stats file if available\n",
    "stats_file = os.path.join(WEBGRAPH_DIR, f\"{VERSION}-domain.stats\")\n",
    "if os.path.exists(stats_file):\n",
    "    try:\n",
    "        with open(stats_file, 'r') as f:\n",
    "            stats = f.read()\n",
    "        for line in stats.strip().split('\\n'):\n",
    "            if line.startswith('nodes='):\n",
    "                print(f\"   ‚úÖ Nodes: {int(line.split('=')[1]):,}\")\n",
    "            elif line.startswith('arcs='):\n",
    "                print(f\"   ‚úÖ Edges: {int(line.split('=')[1]):,}\")\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# Final verdict\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "if all_checks_passed:\n",
    "    print(\"üéâ SETUP COMPLETE!\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nYou're ready to discover domains!\")\n",
    "    print(\"Scroll down to Section 3: Discovery Interface\")\n",
    "else:\n",
    "    print(\"‚ö†Ô∏è SETUP INCOMPLETE\")\n",
    "    print(\"=\"*60)\n",
    "    print(\"\\nPlease re-run the failed setup cells above.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 2: Helper Functions\n",
    "\n",
    "These cells define the discovery functionality. You don't need to modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import subprocess\n",
    "import pandas as pd\n",
    "import os\n",
    "import gzip\n",
    "from typing import List, Dict, Tuple\n",
    "\n",
    "class WebgraphDiscovery:\n",
    "    \"\"\"\n",
    "    Wrapper class for running webgraph discovery using the DiscoveryTool.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, webgraph_dir: str, version: str):\n",
    "        self.webgraph_dir = webgraph_dir\n",
    "        self.version = version\n",
    "        self.jar_path = \"/content/cc-webgraph/target/cc-webgraph-0.1-SNAPSHOT-jar-with-dependencies.jar\"\n",
    "        self.tool_class_path = \"/content/NetNeighbors/bin\"\n",
    "        self.graph_base = os.path.join(webgraph_dir, f\"{version}-domain\")\n",
    "        self.vertices_file = os.path.join(webgraph_dir, f\"{version}-domain-vertices.txt.gz\")\n",
    "        \n",
    "        # Cache for domain validation\n",
    "        self._domain_set = None\n",
    "        \n",
    "    def _load_domain_set(self) -> set:\n",
    "        \"\"\"Load set of all domains in webgraph (for validation)\"\"\"\n",
    "        if self._domain_set is not None:\n",
    "            return self._domain_set\n",
    "        \n",
    "        print(\"Loading domain list (one-time, ~30 seconds)...\")\n",
    "        domains = set()\n",
    "        with gzip.open(self.vertices_file, 'rt', encoding='utf-8') as f:\n",
    "            for line in f:\n",
    "                parts = line.strip().split('\\t')\n",
    "                if len(parts) >= 2:\n",
    "                    reversed_domain = parts[1]\n",
    "                    # Convert back to normal notation\n",
    "                    domain = '.'.join(reversed(reversed_domain.split('.')))\n",
    "                    domains.add(domain)\n",
    "        \n",
    "        self._domain_set = domains\n",
    "        print(f\"‚úÖ Loaded {len(domains):,} domains\")\n",
    "        return domains\n",
    "    \n",
    "    def validate_seeds(self, seed_domains: List[str]) -> Tuple[List[str], List[str]]:\n",
    "        \"\"\"Validate which seed domains exist in webgraph\"\"\"\n",
    "        domain_set = self._load_domain_set()\n",
    "        \n",
    "        found = []\n",
    "        not_found = []\n",
    "        \n",
    "        for domain in seed_domains:\n",
    "            domain_clean = domain.strip().lower()\n",
    "            if domain_clean in domain_set:\n",
    "                found.append(domain_clean)\n",
    "            else:\n",
    "                not_found.append(domain_clean)\n",
    "        \n",
    "        return found, not_found\n",
    "    \n",
    "    def discover(self, \n",
    "                 seed_domains: List[str], \n",
    "                 min_connections: int,\n",
    "                 direction: str = 'backlinks') -> pd.DataFrame:\n",
    "        \"\"\"\n",
    "        Run discovery algorithm using the DiscoveryTool.\n",
    "        \n",
    "        Args:\n",
    "            seed_domains: List of seed domain names\n",
    "            min_connections: Minimum number of connections to include in results\n",
    "            direction: 'backlinks' (who links TO seeds) or 'outlinks' (who seeds link TO)\n",
    "            \n",
    "        Returns:\n",
    "            DataFrame with columns: domain, connections, percentage\n",
    "        \"\"\"\n",
    "        # Write seeds to file\n",
    "        seeds_file = '/content/seeds.txt'\n",
    "        with open(seeds_file, 'w') as f:\n",
    "            for domain in seed_domains:\n",
    "                f.write(domain.strip().lower() + '\\n')\n",
    "        \n",
    "        results_file = '/content/results.csv'\n",
    "        \n",
    "        # Build Java command\n",
    "        cmd = [\n",
    "            'java',\n",
    "            '-Xmx48g',  # Use 48GB heap\n",
    "            '-cp', f'{self.jar_path}:{self.tool_class_path}',\n",
    "            'DiscoveryTool',\n",
    "            '--graph', self.graph_base,\n",
    "            '--vertices', self.vertices_file,\n",
    "            '--seeds', seeds_file,\n",
    "            '--output', results_file,\n",
    "            '--min-connections', str(min_connections),\n",
    "            '--direction', direction\n",
    "        ]\n",
    "        \n",
    "        print(f\"Running discovery ({direction}, min_connections={min_connections})...\")\n",
    "        print(f\"Seed domains: {len(seed_domains)}\")\n",
    "        print()\n",
    "        \n",
    "        try:\n",
    "            # Run the discovery tool\n",
    "            result = subprocess.run(\n",
    "                cmd, \n",
    "                capture_output=True, \n",
    "                text=True, \n",
    "                timeout=600  # 10 minute timeout\n",
    "            )\n",
    "            \n",
    "            # Print output\n",
    "            if result.stdout:\n",
    "                print(result.stdout)\n",
    "            \n",
    "            if result.returncode != 0:\n",
    "                print(\"Error output:\")\n",
    "                print(result.stderr)\n",
    "                raise Exception(f\"Discovery failed with return code {result.returncode}\")\n",
    "            \n",
    "            # Read results CSV\n",
    "            if os.path.exists(results_file):\n",
    "                df = pd.read_csv(results_file)\n",
    "                return df\n",
    "            else:\n",
    "                print(\"No results file generated\")\n",
    "                return pd.DataFrame(columns=['domain', 'connections', 'percentage'])\n",
    "                \n",
    "        except subprocess.TimeoutExpired:\n",
    "            raise Exception(\"Discovery timed out (>10 minutes). Try fewer seed domains.\")\n",
    "        except Exception as e:\n",
    "            raise Exception(f\"Discovery error: {str(e)}\")\n",
    "\n",
    "# Initialize discovery object\n",
    "VERSION = \"cc-main-2025-26-nov-dec-jan\"\n",
    "discovery = WebgraphDiscovery(WEBGRAPH_DIR, VERSION)\n",
    "\n",
    "print(\"‚úÖ Discovery tools initialized\")\n",
    "print(f\"Graph location: {WEBGRAPH_DIR}\")\n",
    "print(f\"Version: {VERSION}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "## Section 3: Discovery Interface üéØ\n",
    "\n",
    "### Use this form to discover related domains!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import display, HTML, FileLink, clear_output\n",
    "import pandas as pd\n",
    "\n",
    "# Create input widgets\n",
    "domains_input = widgets.Textarea(\n",
    "    value='',\n",
    "    placeholder='Enter seed domains, one per line:\\nexample.com\\ntest.org\\nsample.net',\n",
    "    description='',\n",
    "    layout=widgets.Layout(width='80%', height='200px'),\n",
    "    style={'description_width': '0px'}\n",
    ")\n",
    "\n",
    "min_conn_slider = widgets.IntSlider(\n",
    "    value=5,\n",
    "    min=1,\n",
    "    max=100,\n",
    "    step=1,\n",
    "    description='Min Connections:',\n",
    "    style={'description_width': '150px'},\n",
    "    layout=widgets.Layout(width='60%')\n",
    ")\n",
    "\n",
    "direction_radio = widgets.RadioButtons(\n",
    "    options=[\n",
    "        ('Backlinks (who links TO seeds)', 'backlinks'),\n",
    "        ('Outlinks (who seeds link TO)', 'outlinks')\n",
    "    ],\n",
    "    value='backlinks',\n",
    "    description='Direction:',\n",
    "    style={'description_width': '150px'}\n",
    ")\n",
    "\n",
    "run_button = widgets.Button(\n",
    "    description='üîç Run Discovery',\n",
    "    button_style='success',\n",
    "    layout=widgets.Layout(width='200px', height='40px'),\n",
    "    tooltip='Click to discover related domains'\n",
    ")\n",
    "\n",
    "output_area = widgets.Output()\n",
    "\n",
    "# Display form\n",
    "display(HTML(\"<h2>üìù Discovery Configuration</h2>\"))\n",
    "display(HTML(\"<p><strong>Seed Domains</strong> (one per line):</p>\"))\n",
    "display(domains_input)\n",
    "display(HTML(\"<br>\"))\n",
    "display(min_conn_slider)\n",
    "display(HTML(\"<br>\"))\n",
    "display(direction_radio)\n",
    "display(HTML(\"<br>\"))\n",
    "display(run_button)\n",
    "display(HTML(\"<hr>\"))\n",
    "display(output_area)\n",
    "\n",
    "# Button click handler\n",
    "def on_run_click(b):\n",
    "    output_area.clear_output()\n",
    "    \n",
    "    with output_area:\n",
    "        display(HTML(\"<h3>‚è≥ Processing...</h3>\"))\n",
    "        \n",
    "        # Validate input\n",
    "        domains_text = domains_input.value.strip()\n",
    "        if not domains_text:\n",
    "            print(\"‚ùå Error: Please enter at least one domain\")\n",
    "            return\n",
    "        \n",
    "        seed_domains = [d.strip() for d in domains_text.split('\\n') if d.strip()]\n",
    "        \n",
    "        if len(seed_domains) == 0:\n",
    "            print(\"‚ùå Error: Please enter at least one domain\")\n",
    "            return\n",
    "        \n",
    "        if len(seed_domains) > 1000:\n",
    "            print(\"‚ùå Error: Maximum 1000 domains allowed\")\n",
    "            print(f\"You entered: {len(seed_domains)} domains\")\n",
    "            return\n",
    "        \n",
    "        # Validate seeds exist in webgraph\n",
    "        print(f\"Validating {len(seed_domains)} seed domains...\")\n",
    "        found, not_found = discovery.validate_seeds(seed_domains)\n",
    "        \n",
    "        if len(found) == 0:\n",
    "            print(\"\\n‚ùå Error: None of the seed domains were found in the webgraph\")\n",
    "            print(\"\\nDomains not found:\")\n",
    "            for d in not_found[:10]:\n",
    "                print(f\"  ‚Ä¢ {d}\")\n",
    "            if len(not_found) > 10:\n",
    "                print(f\"  ... and {len(not_found)-10} more\")\n",
    "            return\n",
    "        \n",
    "        if len(not_found) > 0:\n",
    "            print(f\"\\n‚ö†Ô∏è Warning: {len(not_found)} domains not found in webgraph:\")\n",
    "            for d in not_found[:5]:\n",
    "                print(f\"  ‚Ä¢ {d}\")\n",
    "            if len(not_found) > 5:\n",
    "                print(f\"  ... and {len(not_found)-5} more\")\n",
    "            print(f\"\\nProceeding with {len(found)} valid domains\\n\")\n",
    "        else:\n",
    "            print(f\"‚úÖ All {len(found)} seed domains found in webgraph\\n\")\n",
    "        \n",
    "        print(\"=\"*60)\n",
    "        print(f\"Configuration:\")\n",
    "        print(f\"  ‚Ä¢ Direction: {direction_radio.value}\")\n",
    "        print(f\"  ‚Ä¢ Minimum connections: {min_conn_slider.value}\")\n",
    "        print(f\"  ‚Ä¢ Valid seed domains: {len(found)}\")\n",
    "        print(\"=\"*60)\n",
    "        \n",
    "        try:\n",
    "            # Run discovery\n",
    "            results_df = discovery.discover(\n",
    "                seed_domains=found,\n",
    "                min_connections=min_conn_slider.value,\n",
    "                direction=direction_radio.value\n",
    "            )\n",
    "            \n",
    "            # Clear processing message\n",
    "            clear_output(wait=True)\n",
    "            \n",
    "            # Display results\n",
    "            if len(results_df) == 0:\n",
    "                display(HTML(\"<h3>‚ùå No Results Found</h3>\"))\n",
    "                print(\"No domains found matching the criteria.\")\n",
    "                print(\"\\nTry:\")\n",
    "                print(\"  ‚Ä¢ Lowering the minimum connections threshold\")\n",
    "                print(\"  ‚Ä¢ Using different seed domains\")\n",
    "                print(\"  ‚Ä¢ Switching between backlinks and outlinks\")\n",
    "            else:\n",
    "                display(HTML(f\"<h3>‚úÖ Found {len(results_df):,} Domains</h3>\"))\n",
    "                print(f\"Discovered {len(results_df):,} domains with ‚â•{min_conn_slider.value} connections\\n\")\n",
    "                \n",
    "                # Style and display dataframe\n",
    "                display(HTML(\"<h4>Top Results:</h4>\"))\n",
    "                \n",
    "                styled_df = results_df.head(100).style.format({\n",
    "                    'connections': '{:,.0f}',\n",
    "                    'percentage': '{:.2f}%'\n",
    "                }).background_gradient(subset=['connections'], cmap='YlOrRd')\n",
    "                \n",
    "                display(styled_df)\n",
    "                \n",
    "                if len(results_df) > 100:\n",
    "                    print(f\"\\n(Showing top 100 of {len(results_df):,} results. Download CSV for full list.)\")\n",
    "                \n",
    "                # Summary statistics\n",
    "                print(\"\\n\" + \"=\"*60)\n",
    "                print(\"Summary Statistics:\")\n",
    "                print(f\"  ‚Ä¢ Total discovered: {len(results_df):,} domains\")\n",
    "                print(f\"  ‚Ä¢ Connections range: {results_df['connections'].min():.0f} - {results_df['connections'].max():.0f}\")\n",
    "                print(f\"  ‚Ä¢ Mean connections: {results_df['connections'].mean():.1f}\")\n",
    "                print(f\"  ‚Ä¢ Median connections: {results_df['connections'].median():.0f}\")\n",
    "                print(\"=\"*60)\n",
    "                \n",
    "                # Download link\n",
    "                display(HTML(\"<br><h4>üíæ Download Full Results</h4>\"))\n",
    "                display(FileLink('/content/results.csv', result_html_prefix=\"üì• Click to download: \"))\n",
    "                print(f\"\\nCSV contains all {len(results_df):,} discovered domains\")\n",
    "                \n",
    "        except Exception as e:\n",
    "            clear_output(wait=True)\n",
    "            display(HTML(\"<h3>‚ùå Error During Discovery</h3>\"))\n",
    "            print(f\"Error: {str(e)}\")\n",
    "            print(\"\\nüìù Troubleshooting:\")\n",
    "            print(\"1. Check that all setup cells completed successfully\")\n",
    "            print(\"2. Verify you're using High-RAM runtime\")\n",
    "            print(\"3. Try restarting runtime: Runtime ‚Üí Restart runtime\")\n",
    "            print(\"4. Try with fewer seed domains\")\n",
    "\n",
    "run_button.on_click(on_run_click)\n",
    "\n",
    "print(\"\\nüí° Tip: Start with 10-20 seed domains and min_connections=5 for fast results!\")"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
